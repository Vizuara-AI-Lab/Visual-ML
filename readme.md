# Visual-ML

A production-ready visual machine learning platform that enables users to build, train, and deploy ML models through an intuitive node-based interface. Perfect for students, educators, and ML practitioners who want to understand machine learning workflows visually.

## ğŸš€ Features

### Core Capabilities

- **Visual Pipeline Builder**: Drag-and-drop node-based ML pipeline creation using React Flow
- **Multiple ML Algorithms**: Linear Regression, Logistic Regression, Decision Trees, Random Forest
- **AI-Powered Mentor**: Integrated AI assistant using OpenAI, Anthropic, and Google Gemini for guidance
- **Real-time Collaboration**: Share projects with unique tokens for collaboration
- **Advanced Data Processing**: Complete preprocessing pipeline with encoding, scaling, and feature selection
- **Interactive Visualizations**: Chart.js integration for data exploration and model evaluation
- **Project Management**: Save, load, and manage multiple ML projects
- **Admin Dashboard**: Monitor users and system analytics

### ML Pipeline Components

- Data Upload & Preview
- Missing Value Handling
- Data Cleaning & Transformation
- Feature Encoding (Label, One-Hot, Target)
- Feature Scaling (Standard, MinMax, Robust)
- Feature Selection
- Train/Test Split
- Model Training (Linear/Logistic Regression, Decision Trees, Random Forest)
- Predictions & Evaluation
- Confusion Matrix & Metrics Visualization

## ğŸ—ï¸ Architecture

### Frontend (`/client`)

**Tech Stack:**

- **Framework**: React 19 + TypeScript
- **Build Tool**: Vite
- **State Management**: Zustand
- **Data Fetching**: TanStack Query (React Query)
- **Routing**: React Router v7
- **UI/Styling**: Tailwind CSS v4
- **Visualizations**: Chart.js, React Flow (@xyflow/react)
- **Animations**: Framer Motion
- **Authentication**: Google OAuth 2.0

**Key Features:**

- Code-split lazy loading for optimal performance
- Protected routes for student and admin access
- Real-time toast notifications
- Responsive design
- ESLint + Husky for code quality

### Backend (`/server`)

**Tech Stack:**

- **Framework**: FastAPI
- **Database**: PostgreSQL with SQLAlchemy ORM
- **Migrations**: Alembic
- **Authentication**: JWT with Google OAuth
- **Caching**: Redis
- **Background Tasks**: Celery
- **Storage**: AWS S3
- **ML Libraries**: scikit-learn, pandas, numpy
- **AI Integration**: OpenAI, Anthropic, Google Gemini (via DynaRoute)
- **Logging**: Loguru

**API Structure:**

- `auth_student.py` - Student authentication & registration
- `projects.py` - Project CRUD operations
- `datasets.py` - Dataset upload and management
- `pipelines.py` - ML pipeline execution (traditional)
- `genai_pipelines.py` - AI-powered pipeline execution
- `genai.py` - AI chatbot integration
- `tasks.py` - Background task management
- `sharing.py` - Project sharing functionality
- `knowledge_base.py` - RAG-based knowledge system
- `secrets.py` - Secure secrets management
- `mentor/` - AI Mentor system with personalized guidance

## ğŸ“¦ Installation

### Prerequisites

- Node.js 18+ and npm/yarn
- Python 3.10+
- PostgreSQL 14+
- Redis (for caching and background tasks)
- AWS account (optional, for S3 storage)

### Client Setup

```bash
cd client
npm install
npm run dev
```

The client will run on `http://localhost:5173`

### Server Setup

1. **Install Python dependencies:**

```bash
cd server
uv sync
```

2. **Set up environment variables:**
   Create a `.env` file in the `/server` directory with:

```env
# Database
DATABASE_URL=postgresql://user:password@localhost/visual_ml

# Security
SECRET_KEY=your-secret-key-min-32-chars
GOOGLE_CLIENT_ID=your-google-client-id
GOOGLE_CLIENT_SECRET=your-google-client-secret

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379

# AWS S3 (optional)
USE_S3=true
S3_BUCKET=your-bucket-name
AWS_ACCESS_KEY_ID=your-access-key
AWS_SECRET_ACCESS_KEY=your-secret-key

# AI APIs
OPENAI_API_KEY=your-openai-key
ANTHROPIC_API_KEY=your-anthropic-key
GOOGLE_API_KEY=your-gemini-key
```

3. **Run database migrations:**

```bash
alembic upgrade head
```

4. **Start the server:**

```bash
uvicorn main:app --reload
```

The server will run on `http://localhost:8000`

API documentation available at `http://localhost:8000/docs`

### Background Workers (Optional)

For background task processing:

```bash
celery -A app.workers.celery_app worker --loglevel=info
celery -A app.workers.celery_app beat --loglevel=info
```

## ğŸ—‚ï¸ Project Structure

```
Visual-ML/
â”œâ”€â”€ client/                    # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/              # Main app component & routing
â”‚   â”‚   â”œâ”€â”€ components/       # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ pages/            # Page components (Auth, Dashboard, Playground)
â”‚   â”‚   â”œâ”€â”€ features/         # Feature-specific components
â”‚   â”‚   â”œâ”€â”€ store/            # Zustand state management
â”‚   â”‚   â”œâ”€â”€ hooks/            # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ config/           # Configuration files
â”‚   â”‚   â”œâ”€â”€ utils/            # Utility functions
â”‚   â”‚   â””â”€â”€ types/            # TypeScript type definitions
â”‚   â”œâ”€â”€ public/               # Static assets
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ server/                   # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/v1/          # API endpoints
â”‚   â”‚   â”œâ”€â”€ core/            # Core configuration & security
â”‚   â”‚   â”œâ”€â”€ db/              # Database configuration
â”‚   â”‚   â”œâ”€â”€ models/          # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ schemas/         # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ services/        # Business logic services
â”‚   â”‚   â”œâ”€â”€ ml/              # ML pipeline engine & nodes
â”‚   â”‚   â”‚   â”œâ”€â”€ algorithms/  # ML algorithm implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ nodes/       # Pipeline node definitions
â”‚   â”‚   â”‚   â”œâ”€â”€ providers/   # AI provider integrations
â”‚   â”‚   â”‚   â”œâ”€â”€ engine.py    # Pipeline execution engine
â”‚   â”‚   â”‚   â””â”€â”€ genai_engine.py  # AI-powered pipeline engine
â”‚   â”‚   â”œâ”€â”€ mentor/          # AI Mentor system
â”‚   â”‚   â”œâ”€â”€ tasks/           # Celery background tasks
â”‚   â”‚   â”œâ”€â”€ utils/           # Utility functions
â”‚   â”‚   â””â”€â”€ workers/         # Celery worker configuration
â”‚   â”œâ”€â”€ models/              # Trained model artifacts
â”‚   â”œâ”€â”€ uploads/             # Uploaded datasets
â”‚   â”œâ”€â”€ alembic/             # Database migrations
â”‚   â”œâ”€â”€ main.py              # FastAPI application entry
â”‚   â””â”€â”€ pyproject.toml
â”‚
â””â”€â”€ readme.md                # This file
```

## ğŸ¯ Usage

### For Students

1. **Sign Up/Sign In**: Create an account or use Google OAuth
2. **Create Project**: Start a new ML project from the dashboard
3. **Upload Data**: Upload your CSV dataset
4. **Build Pipeline**: Use the visual node editor to:
   - Preview and clean data
   - Handle missing values
   - Encode categorical features
   - Scale numerical features
   - Split train/test data
   - Train ML models
   - Evaluate results
5. **Get AI Help**: Use the AI Mentor for guidance and explanations
6. **Share Projects**: Generate share links for collaboration

### For Administrators

1. **Admin Login**: Access at `/admin/login`
2. **Monitor Users**: View student analytics and activity
3. **System Overview**: Monitor platform usage and performance

## ğŸ”’ Security Features

- JWT-based authentication with refresh tokens
- Google OAuth 2.0 integration
- Password hashing with Argon2
- CORS protection
- Request validation with Pydantic
- Rate limiting (configurable)
- Secure secrets management
- Environment-based configuration

## ğŸš€ Production Deployment

### Frontend

- Pre-configured for Vercel deployment
- Build: `npm run build`
- Preview: `npm run preview`

### Backend

- WSGI server: Uvicorn with workers
- Database: PostgreSQL with connection pooling
- Caching: Redis for performance
- Storage: AWS S3 for scalability
- Environment: Set `ENVIRONMENT=production`

**Recommended Stack:**

- Frontend: Vercel
- Backend: Railway, Render, or AWS
- Database: Neon, Supabase, or AWS RDS
- Cache/Queue: Redis Cloud or AWS ElastiCache
- Storage: AWS S3

## ğŸ“Š Key Technologies

| Layer        | Technologies                                               |
| ------------ | ---------------------------------------------------------- |
| **Frontend** | React, TypeScript, Vite, TailwindCSS, React Query, Zustand |
| **Backend**  | FastAPI, SQLAlchemy, Pydantic, Celery                      |
| **Database** | PostgreSQL, Redis                                          |
| **ML/AI**    | scikit-learn, pandas, numpy, OpenAI, Anthropic, Gemini     |
| **DevOps**   | Alembic, Uvicorn, Docker-ready                             |
| **Storage**  | AWS S3, Local filesystem                                   |